{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you hit a problem with checksums, you can execute the following line first\n",
    "!python -m tensorflow_datasets.scripts.download_and_prepare --register_checksums --datasets=oxford_iiit_pet:3.1.0\n",
    "\n",
    "\n",
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(input_image, input_mask):\n",
    "  '''does a random flip of the image and mask'''\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    input_image = tf.image.flip_left_right(input_image)\n",
    "    input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "  return input_image, input_mask\n",
    "\n",
    "\n",
    "def normalize(input_image, input_mask):\n",
    "  '''\n",
    "  normalizes the input image pixel values to be from [0,1].\n",
    "  subtracts 1 from the mask labels to have a range from [0,2]\n",
    "  '''\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  input_mask -= 1\n",
    "  return input_image, input_mask\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint):\n",
    "\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128), method='nearest')\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128), method='nearest')\n",
    "  input_image, input_mask = random_flip(input_image, input_mask)\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask\n",
    "\n",
    "\n",
    "def load_image_test(datapoint):\n",
    "\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128), method='nearest')\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128), method='nearest')\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = dataset['test'].map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "\n",
    "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['pet', 'background', 'outline']\n",
    "\n",
    "\n",
    "def display_with_metrics(display_list, iou_list, dice_score_list):\n",
    "  '''displays a list of images/masks and overlays a list of IOU and Dice Scores'''\n",
    "\n",
    "  metrics_by_id = [(idx, iou, dice_score) for idx, (iou, dice_score) in enumerate(zip(iou_list, dice_score_list)) if iou > 0.0]\n",
    "  metrics_by_id.sort(key=lambda tup: tup[1], reverse=True)  # sorts in place\n",
    "\n",
    "  display_string_list = [\"{}: IOU: {} Dice Score: {}\".format(class_names[idx], iou, dice_score) for idx, iou, dice_score in metrics_by_id]\n",
    "  display_string = \"\\n\\n\".join(display_string_list)\n",
    "\n",
    "  display(display_list, [\"Image\", \"Predicted Mask\", \"True Mask\"], display_string=display_string)\n",
    "\n",
    "\n",
    "def display(display_list,titles=[], display_string=None):\n",
    "  '''displays a list of images/masks'''\n",
    "\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if display_string and i == 1:\n",
    "      plt.xlabel(display_string, fontsize=12)\n",
    "    img_arr = tf.keras.preprocessing.image.array_to_img(display_list[i])\n",
    "    plt.imshow(img_arr)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def show_image_from_dataset(dataset):\n",
    "  '''displays the first image and its mask from a dataset'''\n",
    "\n",
    "  for image, mask in dataset.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "  display([sample_image, sample_mask], titles=[\"Image\", \"True Mask\"])\n",
    "\n",
    "\n",
    "def plot_metrics(metric_name, title, ylim=5):\n",
    "  '''plots a given metric from the model history'''\n",
    "  plt.title(title)\n",
    "  plt.ylim(0,ylim)\n",
    "  plt.plot(model_history.history[metric_name],color='blue',label=metric_name)\n",
    "  plt.plot(model_history.history['val_' + metric_name],color='green',label='val_' + metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_from_dataset(train)\n",
    "show_image_from_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3):\n",
    "\n",
    "  # first layer\n",
    "  x = input_tensor\n",
    "  for i in range(2):\n",
    "    x = tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "            kernel_initializer = 'he_normal', padding = 'same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "\n",
    "def encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=0.3):\n",
    "\n",
    "\n",
    "  f = conv2d_block(inputs, n_filters=n_filters)\n",
    "  p = tf.keras.layers.MaxPooling2D(pool_size=pool_size)(f)\n",
    "  p = tf.keras.layers.Dropout(0.3)(p)\n",
    "\n",
    "  return f, p\n",
    "\n",
    "\n",
    "def encoder(inputs):\n",
    "\n",
    "  f1, p1 = encoder_block(inputs, n_filters=64, pool_size=(2,2), dropout=0.3)\n",
    "  f2, p2 = encoder_block(p1, n_filters=128, pool_size=(2,2), dropout=0.3)\n",
    "  f3, p3 = encoder_block(p2, n_filters=256, pool_size=(2,2), dropout=0.3)\n",
    "  f4, p4 = encoder_block(p3, n_filters=512, pool_size=(2,2), dropout=0.3)\n",
    "\n",
    "  return p4, (f1, f2, f3, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck(inputs):\n",
    "\n",
    "\n",
    "  bottle_neck = conv2d_block(inputs, n_filters=1024)\n",
    "\n",
    "  return bottle_neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, conv_output, n_filters=64, kernel_size=3, strides=3, dropout=0.3):\n",
    "\n",
    "  u = tf.keras.layers.Conv2DTranspose(n_filters, kernel_size, strides = strides, padding = 'same')(inputs)\n",
    "  c = tf.keras.layers.concatenate([u, conv_output])\n",
    "  c = tf.keras.layers.Dropout(dropout)(c)\n",
    "  c = conv2d_block(c, n_filters, kernel_size=3)\n",
    "\n",
    "  return c\n",
    "\n",
    "\n",
    "def decoder(inputs, convs, output_channels):\n",
    "\n",
    "\n",
    "  f1, f2, f3, f4 = convs\n",
    "\n",
    "  c6 = decoder_block(inputs, f4, n_filters=512, kernel_size=(3,3), strides=(2,2), dropout=0.3)\n",
    "  c7 = decoder_block(c6, f3, n_filters=256, kernel_size=(3,3), strides=(2,2), dropout=0.3)\n",
    "  c8 = decoder_block(c7, f2, n_filters=128, kernel_size=(3,3), strides=(2,2), dropout=0.3)\n",
    "  c9 = decoder_block(c8, f1, n_filters=64, kernel_size=(3,3), strides=(2,2), dropout=0.3)\n",
    "\n",
    "  outputs = tf.keras.layers.Conv2D(output_channels, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3\n",
    "\n",
    "def unet():\n",
    "  '''\n",
    "  Defines the UNet by connecting the encoder, bottleneck and decoder.\n",
    "  '''\n",
    "\n",
    "  # specify the input shape\n",
    "  inputs = tf.keras.layers.Input(shape=(128, 128,3,))\n",
    "\n",
    "  # feed the inputs to the encoder\n",
    "  encoder_output, convs = encoder(inputs)\n",
    "\n",
    "  # feed the encoder output to the bottleneck\n",
    "  bottle_neck = bottleneck(encoder_output)\n",
    "\n",
    "  # feed the bottleneck and encoder block outputs to the decoder\n",
    "  # specify the number of classes via the `output_channels` argument\n",
    "  outputs = decoder(bottle_neck, convs, output_channels=OUTPUT_CHANNELS)\n",
    "\n",
    "  # create the model\n",
    "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "  return model\n",
    "\n",
    "# instantiate the model\n",
    "model = unet()\n",
    "\n",
    "# see the resulting model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "EPOCHS = 10\n",
    "VAL_SUBSPLITS = 5\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "# this will take around 20 minutes to run\n",
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(\"loss\", title=\"Training vs Validation Loss\", ylim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_image_and_annotation_arrays():\n",
    "  '''\n",
    "  Unpacks the test dataset and returns the input images and segmentation masks\n",
    "  '''\n",
    "\n",
    "  ds = test_dataset.unbatch()\n",
    "  ds = ds.batch(info.splits['test'].num_examples)\n",
    "\n",
    "  images = []\n",
    "  y_true_segments = []\n",
    "\n",
    "  for image, annotation in ds.take(1):\n",
    "    y_true_segments = annotation.numpy()\n",
    "    images = image.numpy()\n",
    "\n",
    "  y_true_segments = y_true_segments[:(info.splits['test'].num_examples - (info.splits['test'].num_examples % BATCH_SIZE))]\n",
    "\n",
    "  return images[:(info.splits['test'].num_examples - (info.splits['test'].num_examples % BATCH_SIZE))], y_true_segments\n",
    "\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "  '''\n",
    "  Creates the segmentation mask by getting the channel with the highest probability. Remember that we\n",
    "  have 3 channels in the output of the UNet. For each pixel, the predicition will be the channel with the\n",
    "  highest probability.\n",
    "  '''\n",
    "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0].numpy()\n",
    "\n",
    "\n",
    "def make_predictions(image, mask, num=1):\n",
    "\n",
    "  image = np.reshape(image,(1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "  pred_mask = model.predict(image)\n",
    "  pred_mask = create_mask(pred_mask)\n",
    "\n",
    "  return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_wise_metrics(y_true, y_pred):\n",
    "  class_wise_iou = []\n",
    "  class_wise_dice_score = []\n",
    "\n",
    "  smoothening_factor = 0.00001\n",
    "  for i in range(3):\n",
    "\n",
    "    intersection = np.sum((y_pred == i) * (y_true == i))\n",
    "    y_true_area = np.sum((y_true == i))\n",
    "    y_pred_area = np.sum((y_pred == i))\n",
    "    combined_area = y_true_area + y_pred_area\n",
    "\n",
    "    iou = (intersection + smoothening_factor) / (combined_area - intersection + smoothening_factor)\n",
    "    class_wise_iou.append(iou)\n",
    "\n",
    "    dice_score =  2 * ((intersection + smoothening_factor) / (combined_area + smoothening_factor))\n",
    "    class_wise_dice_score.append(dice_score)\n",
    "\n",
    "  return class_wise_iou, class_wise_dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ground truth from the test set\n",
    "y_true_images, y_true_segments = get_test_image_and_annotation_arrays()\n",
    "\n",
    "# feed the test set to th emodel to get the predicted masks\n",
    "results = model.predict(test_dataset, steps=info.splits['test'].num_examples//BATCH_SIZE)\n",
    "results = np.argmax(results, axis=3)\n",
    "results = results[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_wise_iou, cls_wise_dice_score = class_wise_metrics(y_true_segments, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the IOU for each class\n",
    "for idx, iou in enumerate(cls_wise_iou):\n",
    "  spaces = ' ' * (10-len(class_names[idx]) + 2)\n",
    "  print(\"{}{}{} \".format(class_names[idx], spaces, iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, dice_score in enumerate(cls_wise_dice_score):\n",
    "  spaces = ' ' * (10-len(class_names[idx]) + 2)\n",
    "  print(\"{}{}{} \".format(class_names[idx], spaces, dice_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_slider = 3646\n",
    "\n",
    "\n",
    "y_pred_mask = make_predictions(y_true_images[integer_slider], y_true_segments[integer_slider])\n",
    "\n",
    "\n",
    "iou, dice_score = class_wise_metrics(y_true_segments[integer_slider], y_pred_mask)\n",
    "\n",
    "\n",
    "display_with_metrics([y_true_images[integer_slider], y_pred_mask, y_true_segments[integer_slider]], iou, dice_score) #to show the image with metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
